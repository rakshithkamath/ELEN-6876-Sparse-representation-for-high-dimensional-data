{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spectrum_Sensing2_rk3165.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isruDBuymV-B"
      },
      "source": [
        "# Spectrum Sensing II (Sparse Recovery with LASSO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxDhO3SNnS12"
      },
      "source": [
        "## Looking Ahead\n",
        "\n",
        "In the previous example, we examined the simulated spectral occupancy data in the frequency domain and identified the presence of sparsity. Our techniques for examining the frequency occupancies were analogous to \"classical\" digital methods for spectrum sensing that you might have learned in an undergraduate communications class: one samples at a sufficiently high rate to acquire the entire frequency domain signal, then examines frequency bands of interest.\n",
        "\n",
        "In this exercise, we will instead employ a compressive architecture for spectrum sensing, given that there is frequency sparsity present. This sensing architecture will allow us to sample the signal at a drastically lower rate than the full Nyquist sampling frequency while still being able to reconstruct the frequency occupancies. Please check the homework handout for a more precise writeup of the compressive receiver architecture that we simulate here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq_MOhn9IbC5"
      },
      "source": [
        "## Downloading the Data and Preparing It\n",
        "\n",
        "We download the data file from my Github page again. Then we process it to obtain the zero-one occupancy matrix from the previous homework (code taken from the solutions). Check the previous notebook for the descriptions of the different parameters.\n",
        "\n",
        "**Note**: We are using a different data file in this homework. Instead of white gaussian signal, we use audio signals from $\\href{https://www.upf.edu/web/mtg/irmas}{\\text{IRMAS}}$ dataset. Signals in certain time slots would be a music piece of certain instruments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnSwWwIbgjvg"
      },
      "source": [
        "!git clone https://github.com/tykswtr/instr_ss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC5Xi15AIwwF"
      },
      "source": [
        "import scipy.io as sio\n",
        "import scipy.signal as ssig\n",
        "import numpy as np\n",
        "import numpy.matlib\n",
        "import bokeh.plotting as bpl\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "\n",
        "D = sio.loadmat('/content/instr_ss/ss_instr2_1.mat', squeeze_me=True)\n",
        "\n",
        "## Move dictionary vars into locals\n",
        "B = D['B'] \n",
        "Nslots = D['Nslots']\n",
        "Nuser = D['Nuser']\n",
        "SNR = D['SNR']\n",
        "fmin = D['fmin']\n",
        "fs = D['fs']\n",
        "slot_time = D['slot_time']\n",
        "x = D['x']\n",
        "subband_occupancy = D['subband_occupancy']\n",
        "\n",
        "## Derived parameters\n",
        "fmax = Nuser * B + fmin\n",
        "T = slot_time * Nslots\n",
        "Nsamp = len(x)\n",
        "slot_dur = Nsamp // Nslots\n",
        "## Time and frequency axes\n",
        "f_axis = fs * np.arange(-Nsamp/2+1, Nsamp/2+1)/Nsamp\n",
        "t_axis = Nslots * slot_time * np.arange(0, Nsamp)/Nsamp\n",
        "f_axis = np.squeeze(f_axis)\n",
        "t_axis = np.squeeze(t_axis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDfQi4jEJx2v"
      },
      "source": [
        "## Compute bin edges\n",
        "freq_edges = np.arange(fmin, fmax+B, B) # for in-band\n",
        "slot_edges = np.arange(0, Nsamp + 1, slot_dur)\n",
        "slot_f_axis = f_axis[::Nslots]\n",
        "\n",
        "def freq_power_detector(slot_idx):\n",
        "  # Expect slot_idx in 0, 1, ..., Nslots-1\n",
        "  slot_x = x[slot_edges[slot_idx]:slot_edges[slot_idx+1]]\n",
        "  slot_X = np.fft.fftshift(np.fft.fft(slot_x))\n",
        "  freq_occupancy_powers = np.zeros((Nuser,))\n",
        "  for band_idx in range(Nuser):\n",
        "    subband_mask = np.where((slot_f_axis >= freq_edges[band_idx]) \n",
        "                            & (slot_f_axis <= freq_edges[band_idx+1]))[0]\n",
        "    # occupancy = slot_X[subband_mask]\n",
        "    freq_occupancy_powers[band_idx] = np.mean(20 * np.log10(np.absolute(slot_X[subband_mask])))\n",
        "  return freq_occupancy_powers\n",
        "\n",
        "## Make the 0-1 matrix\n",
        "raw_powers = np.zeros((Nslots, Nuser))\n",
        "for slot_idx in range(Nslots):\n",
        "  raw_powers[slot_idx, :] = freq_power_detector(slot_idx)\n",
        "  \n",
        "thresh = 30\n",
        "up_idx = np.where((raw_powers > thresh))\n",
        "down_idx = np.where((raw_powers <= thresh))\n",
        "occupancies = np.zeros((Nslots, Nuser))\n",
        "occupancies[up_idx] = 1\n",
        "occupancies[down_idx] = 0\n",
        "  \n",
        "subband_sparsities = np.sum(occupancies, axis=1)\n",
        "slot_sparsities = np.sum(occupancies, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idb04arzZDvm"
      },
      "source": [
        "slot1_x = x[0:slot_dur]\n",
        "slot1_X = np.fft.fftshift(np.fft.fft(slot1_x))\n",
        "## We need to downsample the frequency axis to match the shorter slot time\n",
        "slot_f_axis = f_axis[::Nslots]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQgYfD93rjJj"
      },
      "source": [
        "# We can view the sparsity in the frequency domain\n",
        "plt.plot(slot_f_axis, 20 * np.log10(np.absolute(slot1_X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqrAzjTVZN2A"
      },
      "source": [
        "# From the occupacy matrix above, we notice that 55th slot is occupied, let's view its frequency content\n",
        "idx_u = 54;\n",
        "f_center = fmin + idx_u*B + B/2;\n",
        "subband_mask = np.where((slot_f_axis >= f_center-4*B)\n",
        "                           & (slot_f_axis <= f_center+4*B))[0]\n",
        "\n",
        "bpl.output_notebook()\n",
        "h = bpl.figure(title=\"Frequency-domain signal x\")\n",
        "h.xaxis.axis_label = 'Frequency (MHz)'\n",
        "h.yaxis.axis_label = 'Power (dB)'\n",
        "h.line(slot_f_axis[subband_mask] * 1e-6,\n",
        "       20 * np.log10(np.absolute(slot1_X[subband_mask])))\n",
        "bpl.show(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAO7rzBQZqKx"
      },
      "source": [
        "# Given x, we are able to show one subband music by passing it through a low band pass filter\n",
        "# We first modulate it to move its frequency around 0 \n",
        "user_id = 54;\n",
        "f_center = fmin + user_id*B + B/2;\n",
        "t_axis = slot_time * np.arange(0, slot_dur)/slot_dur\n",
        "osc_sigs = np.cos(-2 * np.pi * f_center * t_axis);\n",
        "mod_sub_slot1_x = osc_sigs*slot1_x;\n",
        "\n",
        "# Then pass it through a low pass filter\n",
        "[b, a] = ssig.cheby1(5, 1, B/fs);\n",
        "lp_sub_slot1_x = ssig.lfilter(b, a, mod_sub_slot1_x);\n",
        "\n",
        "# Downsample to get signal back\n",
        "audio_sub_slot1_x = lp_sub_slot1_x[::int(fs/B/2)];\n",
        "Audio(audio_sub_slot1_x,rate=2*B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWa9bSGZIaWt"
      },
      "source": [
        "## Receiver Implementation\n",
        "\n",
        "In this section, we provide an implementation of the compressive receiver architecture we described in the homework writeup. The number of receiver channels is a parameter that we will be able to modify. We also give the sensing matrix A that corresponds to the receiver, based on our mathematical model for the receiver and used for doing sparse recovery. Note however that the receiver itself is implemented using DSP routines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq7TpvppqJPC"
      },
      "source": [
        "First, we create the sensing matrix based on the frequency domain system model we discussed in the homework writeup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfLEA2PIh3Jw"
      },
      "source": [
        "## Set receiver size and sampling parameters\n",
        "m = 32\n",
        "L = int(np.floor(fmax / B))\n",
        "n = 2*L + 1\n",
        "\n",
        "## Create random sign (Rademacher) matrix\n",
        "S = (np.random.rand(m, n) > 0.5).astype(int)\n",
        "S = 2 * S - 1\n",
        "## Create system coefficient array\n",
        "## Try it a faster way\n",
        "F = np.fft.fft(np.eye(n))\n",
        "F_reshaped = np.concatenate((F[:, L+1:], F[:, :L+1]), axis=1)\n",
        "d = np.zeros((n,)).astype(np.complex64)\n",
        "for idx_l in range(n):\n",
        "  l_shifted = -L + idx_l\n",
        "  if l_shifted == 0:\n",
        "    d_coeff = 1/n  \n",
        "  else:\n",
        "    d_coeff = 1/(1j*2*np.pi*l_shifted)*(1 - np.exp(-1j*2*np.pi*l_shifted/n))\n",
        "  d[idx_l] = d_coeff\n",
        "D = np.diag(d)\n",
        "C = np.dot(np.dot(S, F_reshaped), D)\n",
        "\n",
        "## Create sensing matrix\n",
        "A = np.conj(C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajP7MZhlqO5o"
      },
      "source": [
        "Next, we implement the receiver's action on our input signal using DSP routines. Since we are performing a digital simulation, our low-pass antialiasing filter is not ideal; we try to make it as close as possible to ideal by using many filter coefficients, and we also change the rate (decimate) after filtering for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaUj7Er6qldn"
      },
      "source": [
        "## Implement the sign-alternating mixing functions.\n",
        "## Given our choices, these signals have rate nB, which can be shown equals fs. (nyquist rate)\n",
        "## So we don't need to interpolate anything: just periodically extend.\n",
        "p_seqs = np.matlib.repmat(S, 1, int(len(x)/n))\n",
        "# Mix the input with the sign-alternating functions.\n",
        "x_mix = x * p_seqs\n",
        "# Design the low pass filters. For efficiency, just use a single filter for all branches.\n",
        "ds_factor = int(fs/B)\n",
        "x_ds = ssig.decimate(x_mix, ds_factor, ftype='fir', axis=1)\n",
        "y = ds_factor * x_ds  # Preserve approximately the energy of original signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9mOyip7v-lZ"
      },
      "source": [
        "\n",
        "\n",
        "We have a downsampling rate close to the user number. This large reduction in samples was possible because each user's bandwidth is very small compared to the maximum frequency in the multiplexing scheme.\n",
        "\n",
        "Note, however, that the rate of the mixing sequences is required to be very high: equal to the Nyquist rate, in fact. In applications at the GHz scale, this may not be feasible. More modern compressive receiver architectures than the one we implement here exist, which address this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYGveIiLhNIc"
      },
      "source": [
        "### A Key Implementation Point\n",
        "\n",
        "Note that the measurement matrix `A` we have generated does **not** have number of columns equal to `Nuser`: it actually has `2*Nuser + 13` columns. This is because our receiever has a low-pass architecture: it resolves the entire frequency spectrum from `-fmax` to `fmax`, so in particular it contains two elements for each positive frequency band in our band of interest `[fmin, fmax]`! It also contains **extra** bands' frequency content, in particular the spectrum from `-fmin` to `fmin`, which accounts for the extra `13` columns.\n",
        "\n",
        "It is very important to take this into account below, when doing detection tasks with your LASSO recovery algorithm. In particular, you should look at both the first `128` and the last `128` elements of the output vector in order to see what the frequency occupancies are in our band of interest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRQwhrwOhf8Q"
      },
      "source": [
        "A.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvlaOC1qwpvn"
      },
      "source": [
        "## Signal Recovery\n",
        "\n",
        "We now have our measurements from the receiver `y`, and our model of the linear mapping implemented by the receiver `A`. We can solve the LASSO problem using the proximal gradient algorithm, as described in the homework writeup, in order to attempt to recover the original spectral occupancies.\n",
        "\n",
        "As input to the LASSO algorithm, we need to give a single measured vector y, but for each slot we have numerous samples in our output `y` created above. In this assignment, we will use a naive approach to doing this: we create a single input for the LASSO solver by simply taking a random summation over the `slot_dur_ds` vectors in `y`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS66W45sxC8G"
      },
      "source": [
        "# For our tasks belowe, we try to focus on the first slot. You can change the code to work on other slots\n",
        "slot_idx = 0\n",
        "slot_dur_ds = int(slot_dur / ds_factor)\n",
        "y_slot = y[:, slot_dur_ds*slot_idx:slot_dur_ds*(slot_idx+1)]\n",
        "\n",
        "true_occupancies = occupancies[slot_idx, :] # Our ground-truth occupancies, for assessment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebUtyDGRcTB8"
      },
      "source": [
        "## random summation and the true X\n",
        "\n",
        "As we mentioned in the homework handout, we can consider $Y(f) = A X(f)$, where $X(f)$ is sparse. In practice, it would be more efficient if we are able to deal with time domain signal $y$ which is the same $y$ we have in the code. However, our measurement $y$ have the same length as downsampled $x$, and maybe we don't want to put everying in our Lasso solver directly. What we do here is some naive projection. Assume $r$ is a random complex gaussian, then You can consider our measurement `lasso_input_y` as $\\text{lasso_input_y} = Y(f) F r = A X(f) F r$, where $F$ is the inverse DFT matrix. As Fourier transfer preserves norm, we can consider $X(f)F$ also be sparse, and hope a random projection does not affect sparsity. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6uoQMycHZk"
      },
      "source": [
        "# We take our lasso input as a random projection by mixing it with a complex gaussian noise\n",
        "rand_pj = np.random.randn(y_slot.shape[-1], ) + 1j * np.random.randn(y_slot.shape[-1], )\n",
        "lasso_input_y = y_slot.dot(rand_pj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KuuRfOQejmU"
      },
      "source": [
        "# Based on the logic above, we can try to visualize the sparsity of our true X \n",
        "slot_x = x[slot_edges[slot_idx]:slot_edges[slot_idx+1]]\n",
        "slot_X = np.fft.fftshift(np.fft.fft(slot_x))\n",
        "slot_MX = slot_X.reshape((-1, y_slot.shape[-1]));\n",
        "slot_xx = np.fft.ifft(np.fft.ifftshift(slot_MX, axes=1))\n",
        "true_x = np.dot(slot_xx, rand_pj)\n",
        "x_supp = np.where(np.abs(true_x) > 1/10*np.max(true_x))[0]\n",
        "plt.stem(np.abs(true_x), use_line_collection=True)\n",
        "# You should tell that for most random projection, this should be (with high chance) consistent with occupacy matrix\n",
        "print(\"support of x: {}\".format(x_supp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHRGCF-xhLOT"
      },
      "source": [
        "### Recovery of Signal After Knowing the Support\n",
        "\n",
        "Our task here for spectrum sensing is mainly a support recovery. We care more about the support of our solution $x$ than its actual value. For many engineering applications, support recovery is of great importance. The goal is know which frequency bands are available, so that we can avoid interfering with other users. From above, we have shown one example how you can get the subband music through a low pass filter. Here we show another way to recovering the signal from our measurements directly. \n",
        "\n",
        "Notice that our `lasso_input_y` is only a random projection of the true signal, so it does not contains all the time domain information. To recover it, instead of running multiple sparse recovery problem, we can utilize the information of support. We know that $Y(f) = A X(f)$, where `A` is a wide $m \\times n$ matrix and thus underermined. Once we are able to know the support, we can get $A_S$ by only chosing the columns our signal is supported on. Thus `A` becomes a $m \\times k$ matrix, where $k$ is the size of the support. We can find our `X` by simply $X(f) = A^{\\dagger} Y(f)$. Here $A^{\\dagger}$ is the pseudo inverse. We try to show the example below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMzW28wvkTvL"
      },
      "source": [
        "# The below code is for slot 1 and band 55th, you can alter the code if want to listen to something different\n",
        "tru_x_supp = np.array([30, 31, 73, 84, 103, 165, 184, 195, 237, 238])\n",
        "A_tall = A[:, tru_x_supp]\n",
        "A_tall_inv = np.linalg.pinv(A_tall)\n",
        "pred_x = A_tall_inv.dot(y_slot)\n",
        "# we can hear the music piece we have above directly through one channel\n",
        "Audio(np.real(pred_x[-3, :]),rate=B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w6wrPN-dxqE"
      },
      "source": [
        "## Your Tasks\n",
        "\n",
        "Below, you are only required to complete the tasks for the **first slot**, using the variable `lasso_input_y` generated above. You can evaluate your algorithm for the other slots, too, if you want.\n",
        "\n",
        "Complete each level three header below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0acV5sOetZ7"
      },
      "source": [
        "### Task 1: Implementing Proximal Gradient Descent for the LASSO Objective\n",
        "\n",
        "Using the proximal gradient iteration given in the homework writeup (and after calculating and implementing the proximal operator for the scaled L1 norm yourself), write code to solve the LASSO problem to recover the frequency occupancies from the input data `lasso_input_y` and `A` that we generated with our simulated receiever above.\n",
        "\n",
        "To check that your algorithm is working properly, it is a good idea to keep track of the objective value (equation (6) in the writeup) at each iteration. After you run your algorithm for the maximum number of iterations, plot the objective value and make sure it is decreasing and leveling off. If it isn't, your algorithm likely has a bug, or you need to run it for more iterations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxIter = 1e5\n",
        "tolerance = 1e-5\n",
        "\n",
        "alpha = np.linalg.norm(A, ord = 2) ** 2\n",
        "alpha = 1 / alpha \n",
        "lambdas_list =[0.0001,0.0002,0.0005,0.0007]\n",
        "\n",
        "iterations_list = {}\n",
        "loss_list = {}\n",
        "x_list = {}\n",
        "final_loss_list = {}\n",
        "\n",
        "\n",
        "\n",
        "for lambda1 in lambdas_list:\n",
        "\n",
        "  print(f\"For lambda = {str(lambda1)}.....\")\n",
        "\n",
        "  count = 0\n",
        "  toleranceCount = 0\n",
        "  x_k= np.zeros(A.shape[1], dtype = np.complex128)\n",
        "  loss = []\n",
        "\n",
        "  while(count < maxIter):\n",
        "\n",
        "    gradient = np.dot(np.transpose(np.conjugate(A)), (np.dot(A, x_k) - lasso_input_y))\n",
        "    w = x_k - alpha * gradient\n",
        "\n",
        "    magnitude = np.maximum(np.absolute(w) - alpha * lambda1, np.zeros(w.shape))\n",
        "    phase = np.angle(w)\n",
        "\n",
        "    x_k = (magnitude * np.cos(phase)) + 1j * (magnitude * np.sin(phase))\n",
        "\n",
        "    loss.append((0.5 * (np.linalg.norm(np.dot(A, x_k) - lasso_input_y) ** 2)) + (lambda1 * np.linalg.norm(x_k, ord = 1)))\n",
        "\n",
        "    if toleranceCount < 10:\n",
        "      if (count > 0) and (abs(loss[count] - loss[count-1]) < tolerance):\n",
        "         toleranceCount += 1\n",
        "      \n",
        "      else:\n",
        "        toleranceCount = 0\n",
        "        count = count + 1\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  iterations_list[lambda1] = count\n",
        "  loss_list[lambda1] = loss\n",
        "  final_loss_list[loss[-1]] = lambda1\n",
        "  x_list[lambda1] = x_k\n",
        "\n",
        "  print(f\"Total iterations taken for the algorithm to converge:{str(count)}\")\n",
        "  print(f\"Final loss value of the algorithm: {str(loss[-1])}\")\n",
        "\n",
        "  plt.figure()\n",
        "  plt.title(f\"Plot for lambda = {str(lambda1)}\")\n",
        "  plt.plot(range(len(loss)), loss)\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"loss\")\n"
      ],
      "metadata": {
        "id": "A-zOfySKAtx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lambda = final_loss_list[min(final_loss_list.keys())]\n",
        "x_output = x_list[best_lambda]\n",
        "loss_final = loss_list[best_lambda]\n",
        "\n",
        "print(f\"Best value of lambda: {str(best_lambda)}\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_final)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Cost\")"
      ],
      "metadata": {
        "id": "S1-fL5lqf_3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAXRWvdYfULQ"
      },
      "source": [
        "### Task 2: Assessing the Detection Performance of our Recovery Algorithm\n",
        "\n",
        "Now that you have an algorithm implemented for performing sparse recovery of the spectral occupancies, perform the following tasks to assess its performance:\n",
        "1. Create a spectral occupancy detector by picking a fixed threshold value: entries in the vector `x` returned by your LASSO recovery algorithm that have powers (magnitude-squared) larger than the threshold correspond to bands that are \"occupied\", and those lower than the threshold are not. Using this threshold detector, convert your LASSO outputs to zero-one vectors. Remember to discard the entries that correspond to frequency bands outside our band of interest `[fmin, fmax]`.\n",
        "2. Compute the error rate for your detector: this is the total number of false detection from your detector compared to the true occupacy matrix. \n",
        "3. Above, we set the variable `m` to determine the number of measurement branches in our system. repeat the above process a few (at least three) times for two different `m` of your choices (for example, `16`, `48`, `64`). What can you say about the result here?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.4\n",
        "\n",
        "output_vector = np.zeros(true_occupancies.shape)\n",
        "mask = np.where(np.abs(x_output[-128:])**2 > threshold * np.max(np.abs(x_output[-128:])**2))[0]\n",
        "output_vector[mask] = 1\n",
        "\n",
        "print(f\"Indices which are occupied according to output vector: {np.where(output_vector == 1)[0]}\")\n",
        "print(f\"Indices which are occupied according to true occupanices vector: {np.where(true_occupancies == 1)[0]}\")\n",
        "\n",
        "mismatch = np.where(output_vector != true_occupancies)[0]\n",
        "print(f\"Indexes which aren't matching: {mismatch}\")\n",
        "print(f\"Error rate in Percentage: {100 * len(mismatch)/len(output_vector)} \")"
      ],
      "metadata": {
        "id": "okYxwn6YfO-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Doing the same process for m=16"
      ],
      "metadata": {
        "id": "grh-dtLgyCri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set receiver size and sampling parameters\n",
        "m = 16\n",
        "L = int(np.floor(fmax / B))\n",
        "n = 2*L + 1\n",
        "\n",
        "## Create random sign (Rademacher) matrix\n",
        "S = (np.random.rand(m, n) > 0.5).astype(int)\n",
        "S = 2 * S - 1\n",
        "## Create system coefficient array\n",
        "## Try it a faster way\n",
        "F = np.fft.fft(np.eye(n))\n",
        "F_reshaped = np.concatenate((F[:, L+1:], F[:, :L+1]), axis=1)\n",
        "d = np.zeros((n,)).astype(np.complex64)\n",
        "for idx_l in range(n):\n",
        "  l_shifted = -L + idx_l\n",
        "  if l_shifted == 0:\n",
        "    d_coeff = 1/n  \n",
        "  else:\n",
        "    d_coeff = 1/(1j*2*np.pi*l_shifted)*(1 - np.exp(-1j*2*np.pi*l_shifted/n))\n",
        "  d[idx_l] = d_coeff\n",
        "D = np.diag(d)\n",
        "C = np.dot(np.dot(S, F_reshaped), D)\n",
        "\n",
        "## Create sensing matrix\n",
        "A = np.conj(C)"
      ],
      "metadata": {
        "id": "kBqTUG4pyGTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Implement the sign-alternating mixing functions.\n",
        "## Given our choices, these signals have rate nB, which can be shown equals fs. (nyquist rate)\n",
        "## So we don't need to interpolate anything: just periodically extend.\n",
        "p_seqs = np.matlib.repmat(S, 1, int(len(x)/n))\n",
        "# Mix the input with the sign-alternating functions.\n",
        "x_mix = x * p_seqs\n",
        "# Design the low pass filters. For efficiency, just use a single filter for all branches.\n",
        "ds_factor = int(fs/B)\n",
        "x_ds = ssig.decimate(x_mix, ds_factor, ftype='fir', axis=1)\n",
        "y = ds_factor * x_ds  # Preserve approximately the energy of original signal"
      ],
      "metadata": {
        "id": "UtVnhmuYyisB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape\n"
      ],
      "metadata": {
        "id": "TNpAXY87ykux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For our tasks belowe, we try to focus on the first slot. You can change the code to work on other slots\n",
        "slot_idx = 0\n",
        "slot_dur_ds = int(slot_dur / ds_factor)\n",
        "y_slot = y[:, slot_dur_ds*slot_idx:slot_dur_ds*(slot_idx+1)]\n",
        "\n",
        "true_occupancies = occupancies[slot_idx, :] # Our ground-truth occupancies, for assessment"
      ],
      "metadata": {
        "id": "udMwJjlYyn7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We take our lasso input as a random projection by mixing it with a complex gaussian noise\n",
        "rand_pj = np.random.randn(y_slot.shape[-1], ) + 1j * np.random.randn(y_slot.shape[-1], )\n",
        "lasso_input_y = y_slot.dot(rand_pj)"
      ],
      "metadata": {
        "id": "Ir7It6_kys5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the logic above, we can try to visualize the sparsity of our true X \n",
        "slot_x = x[slot_edges[slot_idx]:slot_edges[slot_idx+1]]\n",
        "slot_X = np.fft.fftshift(np.fft.fft(slot_x))\n",
        "slot_MX = slot_X.reshape((-1, y_slot.shape[-1]));\n",
        "slot_xx = np.fft.ifft(np.fft.ifftshift(slot_MX, axes=1))\n",
        "true_x = np.dot(slot_xx, rand_pj)\n",
        "x_supp = np.where(np.abs(true_x) > 1/10*np.max(true_x))[0]\n",
        "plt.stem(np.abs(true_x), use_line_collection=True)\n",
        "# You should tell that for most random projection, this should be (with high chance) consistent with occupacy matrix\n",
        "print(\"support of x: {}\".format(x_supp))"
      ],
      "metadata": {
        "id": "V95al99pyvVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The below code is for slot 1 and band 55th, you can alter the code if want to listen to something different\n",
        "tru_x_supp = np.array([30, 31, 73, 84, 103, 165, 184, 195, 237, 238])\n",
        "A_tall = A[:, tru_x_supp]\n",
        "A_tall_inv = np.linalg.pinv(A_tall)\n",
        "pred_x = A_tall_inv.dot(y_slot)\n",
        "# we can hear the music piece we have above directly through one channel\n",
        "Audio(np.real(pred_x[-3, :]),rate=B)"
      ],
      "metadata": {
        "id": "9tb3tC-Vyzh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxIter = 1e5\n",
        "tolerance = 1e-5\n",
        "\n",
        "alpha = np.linalg.norm(A, ord = 2) ** 2\n",
        "alpha = 1 / alpha \n",
        "lambdas_list =[0.0001,0.0002,0.0005,0.0007]\n",
        "\n",
        "iterations_list = {}\n",
        "loss_list = {}\n",
        "x_list = {}\n",
        "final_loss_list = {}\n",
        "\n",
        "\n",
        "\n",
        "for lambda1 in lambdas_list:\n",
        "\n",
        "  print(f\"For lambda = {str(lambda1)}.....\")\n",
        "\n",
        "  count = 0\n",
        "  toleranceCount = 0\n",
        "  x_k= np.zeros(A.shape[1], dtype = np.complex128)\n",
        "  loss = []\n",
        "\n",
        "  while(count < maxIter):\n",
        "\n",
        "    gradient = np.dot(np.transpose(np.conjugate(A)), (np.dot(A, x_k) - lasso_input_y))\n",
        "    w = x_k - alpha * gradient\n",
        "\n",
        "    magnitude = np.maximum(np.absolute(w) - alpha * lambda1, np.zeros(w.shape))\n",
        "    phase = np.angle(w)\n",
        "\n",
        "    x_k = (magnitude * np.cos(phase)) + 1j * (magnitude * np.sin(phase))\n",
        "\n",
        "    loss.append((0.5 * (np.linalg.norm(np.dot(A, x_k) - lasso_input_y) ** 2)) + (lambda1 * np.linalg.norm(x_k, ord = 1)))\n",
        "\n",
        "    if toleranceCount < 10:\n",
        "      if (count > 0) and (abs(loss[count] - loss[count-1]) < tolerance):\n",
        "         toleranceCount += 1\n",
        "      \n",
        "      else:\n",
        "        toleranceCount = 0\n",
        "        count = count + 1\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  iterations_list[lambda1] = count\n",
        "  loss_list[lambda1] = loss\n",
        "  final_loss_list[loss[-1]] = lambda1\n",
        "  x_list[lambda1] = x_k\n",
        "\n",
        "  print(f\"Total iterations taken for the algorithm to converge:{str(count)}\")\n",
        "  print(f\"Final loss value of the algorithm: {str(loss[-1])}\")\n"
      ],
      "metadata": {
        "id": "uomunG6Oy2VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lambda = final_loss_list[min(final_loss_list.keys())]\n",
        "x_output = x_list[best_lambda]\n",
        "loss_final = loss_list[best_lambda]\n",
        "\n",
        "print(f\"Best value of lambda: {str(best_lambda)}\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_final)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Cost\")"
      ],
      "metadata": {
        "id": "P27Da2nly_JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.4\n",
        "\n",
        "output_vector = np.zeros(true_occupancies.shape)\n",
        "mask = np.where(np.abs(x_output[-128:])**2 > threshold * np.max(np.abs(x_output[-128:])**2))[0]\n",
        "output_vector[mask] = 1\n",
        "\n",
        "print(f\"Indices which are occupied according to output vector: {np.where(output_vector == 1)[0]}\")\n",
        "print(f\"Indices which are occupied according to true occupanices vector: {np.where(true_occupancies == 1)[0]}\")\n",
        "\n",
        "mismatch = np.where(output_vector != true_occupancies)[0]\n",
        "print(f\"Indexes which aren't matching: {mismatch}\")\n",
        "print(f\"Error rate in Percentage: {100 * len(mismatch)/len(output_vector)} \")"
      ],
      "metadata": {
        "id": "H_RDZgiPzE8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###For M =48"
      ],
      "metadata": {
        "id": "axrAELOxzj3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set receiver size and sampling parameters\n",
        "m = 48\n",
        "L = int(np.floor(fmax / B))\n",
        "n = 2*L + 1\n",
        "\n",
        "## Create random sign (Rademacher) matrix\n",
        "S = (np.random.rand(m, n) > 0.5).astype(int)\n",
        "S = 2 * S - 1\n",
        "## Create system coefficient array\n",
        "## Try it a faster way\n",
        "F = np.fft.fft(np.eye(n))\n",
        "F_reshaped = np.concatenate((F[:, L+1:], F[:, :L+1]), axis=1)\n",
        "d = np.zeros((n,)).astype(np.complex64)\n",
        "for idx_l in range(n):\n",
        "  l_shifted = -L + idx_l\n",
        "  if l_shifted == 0:\n",
        "    d_coeff = 1/n  \n",
        "  else:\n",
        "    d_coeff = 1/(1j*2*np.pi*l_shifted)*(1 - np.exp(-1j*2*np.pi*l_shifted/n))\n",
        "  d[idx_l] = d_coeff\n",
        "D = np.diag(d)\n",
        "C = np.dot(np.dot(S, F_reshaped), D)\n",
        "\n",
        "## Create sensing matrix\n",
        "A = np.conj(C)"
      ],
      "metadata": {
        "id": "uwnLo2uez_yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Implement the sign-alternating mixing functions.\n",
        "## Given our choices, these signals have rate nB, which can be shown equals fs. (nyquist rate)\n",
        "## So we don't need to interpolate anything: just periodically extend.\n",
        "p_seqs = np.matlib.repmat(S, 1, int(len(x)/n))\n",
        "# Mix the input with the sign-alternating functions.\n",
        "x_mix = x * p_seqs\n",
        "# Design the low pass filters. For efficiency, just use a single filter for all branches.\n",
        "ds_factor = int(fs/B)\n",
        "x_ds = ssig.decimate(x_mix, ds_factor, ftype='fir', axis=1)\n",
        "y = ds_factor * x_ds  # Preserve approximately the energy of original signal"
      ],
      "metadata": {
        "id": "2UJOZBoGz_yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape\n"
      ],
      "metadata": {
        "id": "vUGi6J4Cz_yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For our tasks belowe, we try to focus on the first slot. You can change the code to work on other slots\n",
        "slot_idx = 0\n",
        "slot_dur_ds = int(slot_dur / ds_factor)\n",
        "y_slot = y[:, slot_dur_ds*slot_idx:slot_dur_ds*(slot_idx+1)]\n",
        "\n",
        "true_occupancies = occupancies[slot_idx, :] # Our ground-truth occupancies, for assessment"
      ],
      "metadata": {
        "id": "vzYXX5PJz_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We take our lasso input as a random projection by mixing it with a complex gaussian noise\n",
        "rand_pj = np.random.randn(y_slot.shape[-1], ) + 1j * np.random.randn(y_slot.shape[-1], )\n",
        "lasso_input_y = y_slot.dot(rand_pj)"
      ],
      "metadata": {
        "id": "Gsf6rBhmz_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the logic above, we can try to visualize the sparsity of our true X \n",
        "slot_x = x[slot_edges[slot_idx]:slot_edges[slot_idx+1]]\n",
        "slot_X = np.fft.fftshift(np.fft.fft(slot_x))\n",
        "slot_MX = slot_X.reshape((-1, y_slot.shape[-1]));\n",
        "slot_xx = np.fft.ifft(np.fft.ifftshift(slot_MX, axes=1))\n",
        "true_x = np.dot(slot_xx, rand_pj)\n",
        "x_supp = np.where(np.abs(true_x) > 1/10*np.max(true_x))[0]\n",
        "plt.stem(np.abs(true_x), use_line_collection=True)\n",
        "# You should tell that for most random projection, this should be (with high chance) consistent with occupacy matrix\n",
        "print(\"support of x: {}\".format(x_supp))"
      ],
      "metadata": {
        "id": "IlvWhrNrz_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The below code is for slot 1 and band 55th, you can alter the code if want to listen to something different\n",
        "tru_x_supp = np.array([30, 31, 73, 84, 103, 165, 184, 195, 237, 238])\n",
        "A_tall = A[:, tru_x_supp]\n",
        "A_tall_inv = np.linalg.pinv(A_tall)\n",
        "pred_x = A_tall_inv.dot(y_slot)\n",
        "# we can hear the music piece we have above directly through one channel\n",
        "Audio(np.real(pred_x[-3, :]),rate=B)"
      ],
      "metadata": {
        "id": "ZzJhhdvXz_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxIter = 1e5\n",
        "tolerance = 1e-5\n",
        "\n",
        "alpha = np.linalg.norm(A, ord = 2) ** 2\n",
        "alpha = 1 / alpha \n",
        "lambdas_list =[0.0001,0.0002,0.0005,0.0007]\n",
        "\n",
        "iterations_list = {}\n",
        "loss_list = {}\n",
        "x_list = {}\n",
        "final_loss_list = {}\n",
        "\n",
        "\n",
        "\n",
        "for lambda1 in lambdas_list:\n",
        "\n",
        "  print(f\"For lambda = {str(lambda1)}.....\")\n",
        "\n",
        "  count = 0\n",
        "  toleranceCount = 0\n",
        "  x_k= np.zeros(A.shape[1], dtype = np.complex128)\n",
        "  loss = []\n",
        "\n",
        "  while(count < maxIter):\n",
        "\n",
        "    gradient = np.dot(np.transpose(np.conjugate(A)), (np.dot(A, x_k) - lasso_input_y))\n",
        "    w = x_k - alpha * gradient\n",
        "\n",
        "    magnitude = np.maximum(np.absolute(w) - alpha * lambda1, np.zeros(w.shape))\n",
        "    phase = np.angle(w)\n",
        "\n",
        "    x_k = (magnitude * np.cos(phase)) + 1j * (magnitude * np.sin(phase))\n",
        "\n",
        "    loss.append((0.5 * (np.linalg.norm(np.dot(A, x_k) - lasso_input_y) ** 2)) + (lambda1 * np.linalg.norm(x_k, ord = 1)))\n",
        "\n",
        "    if toleranceCount < 10:\n",
        "      if (count > 0) and (abs(loss[count] - loss[count-1]) < tolerance):\n",
        "         toleranceCount += 1\n",
        "      \n",
        "      else:\n",
        "        toleranceCount = 0\n",
        "        count = count + 1\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  iterations_list[lambda1] = count\n",
        "  loss_list[lambda1] = loss\n",
        "  final_loss_list[loss[-1]] = lambda1\n",
        "  x_list[lambda1] = x_k\n",
        "\n",
        "  print(f\"Total iterations taken for the algorithm to converge:{str(count)}\")\n",
        "  print(f\"Final loss value of the algorithm: {str(loss[-1])}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dNaBKu32z_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lambda = final_loss_list[min(final_loss_list.keys())]\n",
        "x_output = x_list[best_lambda]\n",
        "loss_final = loss_list[best_lambda]\n",
        "\n",
        "print(f\"Best value of lambda: {str(best_lambda)}\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_final)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Cost\")"
      ],
      "metadata": {
        "id": "Y871OAT3z_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.3\n",
        "\n",
        "output_vector = np.zeros(true_occupancies.shape)\n",
        "mask = np.where(np.abs(x_output[-128:])**2 > threshold * np.max(np.abs(x_output[-128:])**2))[0]\n",
        "output_vector[mask] = 1\n",
        "\n",
        "print(f\"Indices which are occupied according to output vector: {np.where(output_vector == 1)[0]}\")\n",
        "print(f\"Indices which are occupied according to true occupanices vector: {np.where(true_occupancies == 1)[0]}\")\n",
        "\n",
        "mismatch = np.where(output_vector != true_occupancies)[0]\n",
        "print(f\"Indexes which aren't matching: {mismatch}\")\n",
        "print(f\"Error rate in Percentage: {100 * len(mismatch)/len(output_vector)} \")"
      ],
      "metadata": {
        "id": "9QpZI_LHz_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###For M = 64"
      ],
      "metadata": {
        "id": "QcDDmYgL084a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set receiver size and sampling parameters\n",
        "m = 64\n",
        "L = int(np.floor(fmax / B))\n",
        "n = 2*L + 1\n",
        "\n",
        "## Create random sign (Rademacher) matrix\n",
        "S = (np.random.rand(m, n) > 0.5).astype(int)\n",
        "S = 2 * S - 1\n",
        "## Create system coefficient array\n",
        "## Try it a faster way\n",
        "F = np.fft.fft(np.eye(n))\n",
        "F_reshaped = np.concatenate((F[:, L+1:], F[:, :L+1]), axis=1)\n",
        "d = np.zeros((n,)).astype(np.complex64)\n",
        "for idx_l in range(n):\n",
        "  l_shifted = -L + idx_l\n",
        "  if l_shifted == 0:\n",
        "    d_coeff = 1/n  \n",
        "  else:\n",
        "    d_coeff = 1/(1j*2*np.pi*l_shifted)*(1 - np.exp(-1j*2*np.pi*l_shifted/n))\n",
        "  d[idx_l] = d_coeff\n",
        "D = np.diag(d)\n",
        "C = np.dot(np.dot(S, F_reshaped), D)\n",
        "\n",
        "## Create sensing matrix\n",
        "A = np.conj(C)"
      ],
      "metadata": {
        "id": "pRjNdD7N1BV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Implement the sign-alternating mixing functions.\n",
        "## Given our choices, these signals have rate nB, which can be shown equals fs. (nyquist rate)\n",
        "## So we don't need to interpolate anything: just periodically extend.\n",
        "p_seqs = np.matlib.repmat(S, 1, int(len(x)/n))\n",
        "# Mix the input with the sign-alternating functions.\n",
        "x_mix = x * p_seqs\n",
        "# Design the low pass filters. For efficiency, just use a single filter for all branches.\n",
        "ds_factor = int(fs/B)\n",
        "x_ds = ssig.decimate(x_mix, ds_factor, ftype='fir', axis=1)\n",
        "y = ds_factor * x_ds  # Preserve approximately the energy of original signal"
      ],
      "metadata": {
        "id": "NMCZ0Bg_1BV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape\n"
      ],
      "metadata": {
        "id": "m6Gn7Z1J1BV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For our tasks belowe, we try to focus on the first slot. You can change the code to work on other slots\n",
        "slot_idx = 0\n",
        "slot_dur_ds = int(slot_dur / ds_factor)\n",
        "y_slot = y[:, slot_dur_ds*slot_idx:slot_dur_ds*(slot_idx+1)]\n",
        "\n",
        "true_occupancies = occupancies[slot_idx, :] # Our ground-truth occupancies, for assessment"
      ],
      "metadata": {
        "id": "ZW_UqGgw1BV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We take our lasso input as a random projection by mixing it with a complex gaussian noise\n",
        "rand_pj = np.random.randn(y_slot.shape[-1], ) + 1j * np.random.randn(y_slot.shape[-1], )\n",
        "lasso_input_y = y_slot.dot(rand_pj)"
      ],
      "metadata": {
        "id": "QUDE_AUA1BV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the logic above, we can try to visualize the sparsity of our true X \n",
        "slot_x = x[slot_edges[slot_idx]:slot_edges[slot_idx+1]]\n",
        "slot_X = np.fft.fftshift(np.fft.fft(slot_x))\n",
        "slot_MX = slot_X.reshape((-1, y_slot.shape[-1]));\n",
        "slot_xx = np.fft.ifft(np.fft.ifftshift(slot_MX, axes=1))\n",
        "true_x = np.dot(slot_xx, rand_pj)\n",
        "x_supp = np.where(np.abs(true_x) > 1/10*np.max(true_x))[0]\n",
        "plt.stem(np.abs(true_x), use_line_collection=True)\n",
        "# You should tell that for most random projection, this should be (with high chance) consistent with occupacy matrix\n",
        "print(\"support of x: {}\".format(x_supp))"
      ],
      "metadata": {
        "id": "Gt7pTUE91BV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The below code is for slot 1 and band 55th, you can alter the code if want to listen to something different\n",
        "tru_x_supp = np.array([30, 31, 73, 84, 103, 165, 184, 195, 237, 238])\n",
        "A_tall = A[:, tru_x_supp]\n",
        "A_tall_inv = np.linalg.pinv(A_tall)\n",
        "pred_x = A_tall_inv.dot(y_slot)\n",
        "# we can hear the music piece we have above directly through one channel\n",
        "Audio(np.real(pred_x[-3, :]),rate=B)"
      ],
      "metadata": {
        "id": "y9f4Zgal1BV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxIter = 1e5\n",
        "tolerance = 1e-5\n",
        "\n",
        "alpha = np.linalg.norm(A, ord = 2) ** 2\n",
        "alpha = 1 / alpha \n",
        "lambdas_list =[0.0001,0.0002,0.0005,0.0007]\n",
        "\n",
        "iterations_list = {}\n",
        "loss_list = {}\n",
        "x_list = {}\n",
        "final_loss_list = {}\n",
        "\n",
        "\n",
        "\n",
        "for lambda1 in lambdas_list:\n",
        "\n",
        "  print(f\"For lambda = {str(lambda1)}.....\")\n",
        "\n",
        "  count = 0\n",
        "  toleranceCount = 0\n",
        "  x_k= np.zeros(A.shape[1], dtype = np.complex128)\n",
        "  loss = []\n",
        "\n",
        "  while(count < maxIter):\n",
        "\n",
        "    gradient = np.dot(np.transpose(np.conjugate(A)), (np.dot(A, x_k) - lasso_input_y))\n",
        "    w = x_k - alpha * gradient\n",
        "\n",
        "    magnitude = np.maximum(np.absolute(w) - alpha * lambda1, np.zeros(w.shape))\n",
        "    phase = np.angle(w)\n",
        "\n",
        "    x_k = (magnitude * np.cos(phase)) + 1j * (magnitude * np.sin(phase))\n",
        "\n",
        "    loss.append((0.5 * (np.linalg.norm(np.dot(A, x_k) - lasso_input_y) ** 2)) + (lambda1 * np.linalg.norm(x_k, ord = 1)))\n",
        "\n",
        "    if toleranceCount < 10:\n",
        "      if (count > 0) and (abs(loss[count] - loss[count-1]) < tolerance):\n",
        "         toleranceCount += 1\n",
        "      \n",
        "      else:\n",
        "        toleranceCount = 0\n",
        "        count = count + 1\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  iterations_list[lambda1] = count\n",
        "  loss_list[lambda1] = loss\n",
        "  final_loss_list[loss[-1]] = lambda1\n",
        "  x_list[lambda1] = x_k\n",
        "\n",
        "  print(f\"Total iterations taken for the algorithm to converge:{str(count)}\")\n",
        "  print(f\"Final loss value of the algorithm: {str(loss[-1])}\")\n"
      ],
      "metadata": {
        "id": "7AaCFVbu1BV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lambda = final_loss_list[min(final_loss_list.keys())]\n",
        "x_output = x_list[best_lambda]\n",
        "loss_final = loss_list[best_lambda]\n",
        "\n",
        "print(f\"Best value of lambda: {str(best_lambda)}\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss_final)\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Cost\")"
      ],
      "metadata": {
        "id": "9Oqji6JR1BV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.4\n",
        "\n",
        "output_vector = np.zeros(true_occupancies.shape)\n",
        "mask = np.where(np.abs(x_output[-128:])**2 > threshold * np.max(np.abs(x_output[-128:])**2))[0]\n",
        "output_vector[mask] = 1\n",
        "\n",
        "print(f\"Indices which are occupied according to output vector: {np.where(output_vector == 1)[0]}\")\n",
        "print(f\"Indices which are occupied according to true occupanices vector: {np.where(true_occupancies == 1)[0]}\")\n",
        "\n",
        "mismatch = np.where(output_vector != true_occupancies)[0]\n",
        "print(f\"Indexes which aren't matching: {mismatch}\")\n",
        "print(f\"Error rate in Percentage: {100 * len(mismatch)/len(output_vector)} \")"
      ],
      "metadata": {
        "id": "MLrW2Afx1BV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DlKJZ1vQUvy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}